{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet50_ver1_sj.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1XAQmX5FQ4FqGVVSsHDVNQFfKyANn34iK","authorship_tag":"ABX9TyP2zPVTsPu8yDgGV/23s8Hj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["cd drive/MyDrive/네카라쿠배/딥러닝/프로젝트"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFSFnb7g0h1M","executionInfo":{"status":"ok","timestamp":1640621606200,"user_tz":-540,"elapsed":473,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"883b50a4-4b63-4233-d0c2-b6ac1dd893e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/네카라쿠배/딥러닝/프로젝트'\n","/content/drive/MyDrive/네카라쿠배/딥러닝/프로젝트\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGY0TeI30zFk","executionInfo":{"status":"ok","timestamp":1640621606791,"user_tz":-540,"elapsed":9,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"3f6c8507-998a-4c4f-ecb3-a12a3310e4cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["baseline.ipynb       checkpoiont_128.pt  \u001b[0m\u001b[01;34mopen_224\u001b[0m/  resnet50_v2.pt\n","baseline_result.csv  \u001b[01;34mopen\u001b[0m/               \u001b[01;34mopen_448\u001b[0m/  resnet50_ver1_sj.ipynb\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"zbLPkDudeE5M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이콘 제공 data 로드 Baseline"],"metadata":{"id":"iKCHA_ZO1Dcr"}},{"cell_type":"markdown","source":["## 사용 package 선언"],"metadata":{"id":"h8qZRX8x1Qz0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGgexVns0Yny"},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","from torch import optim\n","from torch import nn\n","\n","from torch.utils.data import Dataset\n","from torchvision.transforms import ToTensor\n","from torchvision import transforms\n","\n","import random\n","from glob import glob\n","import pandas as pd\n","import numpy as np\n","from PIL import Image"]},{"cell_type":"markdown","source":["## 데이터 관련 함수 정의 및 데이터 셋 선언"],"metadata":{"id":"7JBQtekj1PKu"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"0S1E9qBD1_7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import transformers\n","\n","from glob import glob\n","from PIL import Image\n","from torch.utils.data import Dataset\n","from torchvision.transforms import ToTensor\n","from torchvision import transforms\n","\n","\n","def extract_day(file_name):\n","    day = int(file_name.split('.')[-2][-2:])\n","    return day\n","\n","\n","def make_day_array(image_pathes):\n","    day_array = np.array([extract_day(file_name) for file_name in image_pathes])\n","    return day_array\n","\n","\n","def make_image_path_array(root_path=None):\n","    if root_path is None:\n","        bc_directories = glob('./BC/*')\n","        lt_directories = glob('./LT/*')\n","\n","    else:\n","        bc_directories = glob(root_path + 'BC/*')\n","        lt_directories = glob(root_path + 'LT/*')\n","\n","    bc_image_path = []\n","    for bc_path in bc_directories:\n","        images = glob(bc_path + '/*.png')\n","        bc_image_path.extend(images)\n","\n","    lt_image_path = []\n","    for lt_path in lt_directories:\n","        images = glob(lt_path + '/*.png')\n","        lt_image_path.extend(images)\n","\n","    return bc_image_path, lt_image_path\n","\n","\n","def make_dataframe(root_path=None):\n","    bc_image_path, lt_image_path = make_image_path_array(root_path)\n","    bc_day_array = make_day_array(bc_image_path)\n","    lt_day_array = make_day_array(lt_image_path)\n","\n","    bc_df = pd.DataFrame({'file_name': bc_image_path,\n","                          'day': bc_day_array})\n","    bc_df['species'] = 'bc'\n","\n","    lt_df = pd.DataFrame({'file_name': lt_image_path,\n","                          'day': lt_day_array})\n","    lt_df['species'] = 'lt'\n","\n","    total_data_frame = pd.concat([bc_df, lt_df]).reset_index(drop=True)\n","\n","    return total_data_frame\n","\n","\n","def make_combination(length, species, data_frame):\n","    before_file_path = []\n","    after_file_path = []\n","    time_delta = []\n","\n","    for i in range(length):\n","        sample = data_frame[data_frame['species'] == species].sample(2)\n","        after = sample[sample['day'] == max(sample['day'])].reset_index(drop=True)\n","        before = sample[sample['day'] == min(sample['day'])].reset_index(drop=True)\n","\n","        before_file_path.append(before.iloc[0]['file_name'])\n","        after_file_path.append(after.iloc[0]['file_name'])\n","        delta = int(after.iloc[0]['day'] - before.iloc[0]['day'])\n","        time_delta.append(delta)\n","\n","    combination_df = pd.DataFrame({\n","        'before_file_path': before_file_path,\n","        'after_file_path': after_file_path,\n","        'time_delta': time_delta,\n","    })\n","\n","    combination_df['species'] = species\n","\n","    return combination_df\n","\n","\n","class KistDataset(Dataset):\n","    def __init__(self, combination_df, is_test= None):\n","        self.combination_df = combination_df\n","        self.transform = transforms.Compose([\n","            transforms.Resize(224),\n","            transforms.ToTensor()\n","        ])\n","        self.is_test = is_test\n","\n","    def __getitem__(self, idx):\n","        before_image = Image.open(self.combination_df.iloc[idx]['before_file_path']) #before_file_path\n","        after_image = Image.open(self.combination_df.iloc[idx]['after_file_path'])  #after_file_path\n","\n","        before_image = self.transform(before_image)\n","        after_image = self.transform(after_image)\n","        if self.is_test:\n","            return before_image, after_image\n","        time_delta = self.combination_df.iloc[idx]['time_delta']\n","        return before_image, after_image, time_delta\n","\n","    def __len__(self):\n","        return len(self.combination_df)"],"metadata":{"id":"NhMEnKs01B5w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data load"],"metadata":{"id":"KN5OSJi5_h6Q"}},{"cell_type":"code","source":["def seed_everything(seed): # seed 고정\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","\n","seed_everything(2048)\n","\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","lr = 1e-5\n","epochs = 10\n","batch_size = 64\n","valid_batch_size = 50\n","\n","# model = CompareNet().to(device)    # 모델 선언\n","# optimizer = optim.Adam(model.parameters(), lr=lr)  # 옵티마이저 선언\n","\n","########################################################################################################################\n","## 이미지 증강 부분\n","from torchvision.transforms.transforms import RandomRotation\n","# 간단한 데이터 augmentation\n","\n","data_transforms = {\n","    'train_dataset' : transforms.Compose([transforms.Resize([256,256]),\n","                                  transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n","                                  transforms.RandomCrop(224), transforms.RandomRotation(45), transforms.ToTensor(),\n","                                  transforms.Normalize([0.458,0.456,0.406],[0.229,0.224,0.225]) ]),\n","#     'val' : transforms.Compose([transforms.Resize([256,256]),\n","#                                 transforms.RandomCrop(224), transforms.RandomRotation(45), transforms.ToTensor(),\n","#                                 transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])  ])\n","}\n","\n","import os\n","from torchvision.datasets import ImageFolder\n","\n","data_dir = './open_224'\n","\n","image_datasets = {x : ImageFolder(root = os.path.join(data_dir, x),\n","                                  transform = data_transforms[x]) for x in ['train_dataset']}\n","\n","dataloaders = {x : torch.utils.data.DataLoader(image_datasets[x],\n","                                               batch_size = batch_size,\n","                                               shuffle = True,\n","                                               num_workers = 2) for x in ['train_dataset']}\n","\n","dataset_sizes = {x : len(image_datasets[x]) for x in ['train_dataset']}\n","########################################################################################################################\n","\n","total_dataframe = make_dataframe(root_path = \"./open_224/train_dataset/\")\n","\n","bt_combination = make_combination(5000, 'bc', total_dataframe)\n","lt_combination = make_combination(5000, 'lt', total_dataframe)\n","\n","bt_train = bt_combination.iloc[:4500]\n","bt_valid = bt_combination.iloc[4500:]\n","\n","lt_train = lt_combination.iloc[:4500]\n","lt_valid = lt_combination.iloc[4500:]\n","\n","train_set = pd.concat([bt_train, lt_train])\n","valid_set = pd.concat([bt_valid, lt_valid])\n","\n","\n","\n","train_dataset = KistDataset(train_set)\n","valid_dataset = KistDataset(valid_set)\n","\n","train_data_loader = DataLoader(train_dataset,\n","                               batch_size=batch_size,\n","                               shuffle=True)\n","\n","valid_data_loader = DataLoader(valid_dataset,\n","                               batch_size=valid_batch_size)\n"],"metadata":{"id":"a9qyhMuj8N7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"htUhc8v-NGu9","executionInfo":{"status":"ok","timestamp":1640621677206,"user_tz":-540,"elapsed":404,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"4129c4ce-7459-474a-af5d-6ab979384cd4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-da6f9d14-bb62-44b1-b875-7f137a130df7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>before_file_path</th>\n","      <th>after_file_path</th>\n","      <th>time_delta</th>\n","      <th>species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./open_224/train_dataset/BC/BC_02/DAT26.png</td>\n","      <td>./open_224/train_dataset/BC/BC_06/DAT37.png</td>\n","      <td>11</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT11.png</td>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT23.png</td>\n","      <td>12</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./open_224/train_dataset/BC/BC_02/DAT24.png</td>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT33.png</td>\n","      <td>9</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./open_224/train_dataset/BC/BC_09/DAT07.png</td>\n","      <td>./open_224/train_dataset/BC/BC_09/DAT29.png</td>\n","      <td>22</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./open_224/train_dataset/BC/BC_02/DAT04.png</td>\n","      <td>./open_224/train_dataset/BC/BC_07/DAT31.png</td>\n","      <td>27</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4495</th>\n","      <td>./open_224/train_dataset/LT/LT_07/DAT11.png</td>\n","      <td>./open_224/train_dataset/LT/LT_03/DAT34.png</td>\n","      <td>23</td>\n","      <td>lt</td>\n","    </tr>\n","    <tr>\n","      <th>4496</th>\n","      <td>./open_224/train_dataset/LT/LT_06/DAT28.png</td>\n","      <td>./open_224/train_dataset/LT/LT_08/DAT29.png</td>\n","      <td>1</td>\n","      <td>lt</td>\n","    </tr>\n","    <tr>\n","      <th>4497</th>\n","      <td>./open_224/train_dataset/LT/LT_08/DAT05.png</td>\n","      <td>./open_224/train_dataset/LT/LT_10/DAT08.png</td>\n","      <td>3</td>\n","      <td>lt</td>\n","    </tr>\n","    <tr>\n","      <th>4498</th>\n","      <td>./open_224/train_dataset/LT/LT_01/DAT13.png</td>\n","      <td>./open_224/train_dataset/LT/LT_07/DAT24.png</td>\n","      <td>11</td>\n","      <td>lt</td>\n","    </tr>\n","    <tr>\n","      <th>4499</th>\n","      <td>./open_224/train_dataset/LT/LT_03/DAT27.png</td>\n","      <td>./open_224/train_dataset/LT/LT_07/DAT36.png</td>\n","      <td>9</td>\n","      <td>lt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9000 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da6f9d14-bb62-44b1-b875-7f137a130df7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-da6f9d14-bb62-44b1-b875-7f137a130df7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-da6f9d14-bb62-44b1-b875-7f137a130df7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                 before_file_path  ... species\n","0     ./open_224/train_dataset/BC/BC_02/DAT26.png  ...      bc\n","1     ./open_224/train_dataset/BC/BC_01/DAT11.png  ...      bc\n","2     ./open_224/train_dataset/BC/BC_02/DAT24.png  ...      bc\n","3     ./open_224/train_dataset/BC/BC_09/DAT07.png  ...      bc\n","4     ./open_224/train_dataset/BC/BC_02/DAT04.png  ...      bc\n","...                                           ...  ...     ...\n","4495  ./open_224/train_dataset/LT/LT_07/DAT11.png  ...      lt\n","4496  ./open_224/train_dataset/LT/LT_06/DAT28.png  ...      lt\n","4497  ./open_224/train_dataset/LT/LT_08/DAT05.png  ...      lt\n","4498  ./open_224/train_dataset/LT/LT_01/DAT13.png  ...      lt\n","4499  ./open_224/train_dataset/LT/LT_03/DAT27.png  ...      lt\n","\n","[9000 rows x 4 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["bt_combination.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vR1ShFm4KYqL","executionInfo":{"status":"ok","timestamp":1640614415202,"user_tz":-540,"elapsed":501,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"b330f025-083e-480a-97a2-01074381e0d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5e98898b-31da-4017-b9bd-4def165ff1b2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>before_file_path</th>\n","      <th>after_file_path</th>\n","      <th>time_delta</th>\n","      <th>species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./open_224/train_dataset/BC/BC_02/DAT26.png</td>\n","      <td>./open_224/train_dataset/BC/BC_06/DAT37.png</td>\n","      <td>11</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT11.png</td>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT23.png</td>\n","      <td>12</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./open_224/train_dataset/BC/BC_02/DAT24.png</td>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT33.png</td>\n","      <td>9</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./open_224/train_dataset/BC/BC_09/DAT07.png</td>\n","      <td>./open_224/train_dataset/BC/BC_09/DAT29.png</td>\n","      <td>22</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./open_224/train_dataset/BC/BC_02/DAT04.png</td>\n","      <td>./open_224/train_dataset/BC/BC_07/DAT31.png</td>\n","      <td>27</td>\n","      <td>bc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e98898b-31da-4017-b9bd-4def165ff1b2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5e98898b-31da-4017-b9bd-4def165ff1b2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5e98898b-31da-4017-b9bd-4def165ff1b2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                              before_file_path  ... species\n","0  ./open_224/train_dataset/BC/BC_02/DAT26.png  ...      bc\n","1  ./open_224/train_dataset/BC/BC_01/DAT11.png  ...      bc\n","2  ./open_224/train_dataset/BC/BC_02/DAT24.png  ...      bc\n","3  ./open_224/train_dataset/BC/BC_09/DAT07.png  ...      bc\n","4  ./open_224/train_dataset/BC/BC_02/DAT04.png  ...      bc\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["total_dataframe.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"X2GJFXPUKSTP","executionInfo":{"status":"ok","timestamp":1640614418797,"user_tz":-540,"elapsed":597,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"c87095d4-ba24-469e-dc60-857fc7528977"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0ad7bf4a-7278-4537-b9c8-8eba9b48ab29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>day</th>\n","      <th>species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT04.png</td>\n","      <td>4</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT09.png</td>\n","      <td>9</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT03.png</td>\n","      <td>3</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT10.png</td>\n","      <td>10</td>\n","      <td>bc</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./open_224/train_dataset/BC/BC_01/DAT12.png</td>\n","      <td>12</td>\n","      <td>bc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ad7bf4a-7278-4537-b9c8-8eba9b48ab29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ad7bf4a-7278-4537-b9c8-8eba9b48ab29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ad7bf4a-7278-4537-b9c8-8eba9b48ab29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                     file_name  day species\n","0  ./open_224/train_dataset/BC/BC_01/DAT04.png    4      bc\n","1  ./open_224/train_dataset/BC/BC_01/DAT09.png    9      bc\n","2  ./open_224/train_dataset/BC/BC_01/DAT03.png    3      bc\n","3  ./open_224/train_dataset/BC/BC_01/DAT10.png   10      bc\n","4  ./open_224/train_dataset/BC/BC_01/DAT12.png   12      bc"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["for step, (before_image, after_image, time_delta) in tqdm(enumerate(train_data_loader)):\n","    print(step)\n","    print(before_image)\n","    print(after_image)\n","    print(time_delta)\n","    break"],"metadata":{"id":"VTCZ4NRiMbcj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 선언\n"],"metadata":{"id":"hc1naZMj_-lC"}},{"cell_type":"code","source":["class Resnet(nn.Module):\n","\n","    def __init__(self, embedding_dimension=1, pretrained=True):\n","        super().__init__()\n","        self.model = models.resnet50(pretrained = pretrained)\n","        \n","        input_features_fc_layer = self.model.fc.in_features\n","        self.model.fc = nn.Linear(input_features_fc_layer, embedding_dimension, bias = False)\n","        self.before_net = self.model\n","        self.after_net = self.model\n","        \n","    def forward(self, before_input, after_input):\n","        before = self.before_net(before_input)\n","        after = self.after_net(after_input)\n","        delta = before - after\n","        return delta\n","    "],"metadata":{"id":"VvqwXH_bdlGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Resnet(nn.Module):\n","\n","    def __init__(self):\n","        super(Resnet, self).__init__()\n","        self.before_net = models.resnet50(pretrained=True)\n","        self.after_net = models.resnet50(pretrained=True)\n","        \n","    def forward(self, before_input, after_input):\n","        before = self.before_net(before_input)\n","        after = self.after_net(after_input)\n","        delta = before - after\n","        return delta\n","    "],"metadata":{"id":"V5hUy1rmUOIX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pretrained model load (resnet50)"],"metadata":{"id":"mmVtk6x1ATJF"}},{"cell_type":"code","source":["## pretrained 된 모델들을 불러올 수 있다\n","import torch\n","from torch import nn\n","from torchvision import models\n","\n","resnet = Resnet()  # True = weights도 같이\n","# num_ftrs = resnet.fc.in_features        # 출력층의 최종 클래스 갯수\n","# resnet.fc = nn.Linear(num_ftrs, 1)     # pretrained 된 최종 클래스 수와 우리 데이터의 최종 클래스 수를 맞춰주기\n","resnet = resnet.to(device)\n","\n","criterion = nn.L1Loss()\n","optimizer_ft = optim.Adam(filter(lambda p : p.requires_grad, resnet.parameters()), lr = 0.001)\n","# 마지막으로 최종 클래스 수를 변환하는 과정에서 학습하기 위한 코드\n","\n","from torch.optim import lr_scheduler\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma = 0.1)"],"metadata":{"id":"I2EBj-_O8N2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0\n","for child in resnet.children():\n","    print(i)\n","    print(child)\n","    print('-'*30)\n","    i += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCo-tuXApp_G","executionInfo":{"status":"ok","timestamp":1640621695144,"user_tz":-540,"elapsed":519,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"dcc68fc1-9e2a-445e-b052-8e7796fcb7b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=1, bias=False)\n",")\n","------------------------------\n"]}]},{"cell_type":"code","source":["## 특정 레이어는 고정시키기\n","## 입력에 가까운 레이어 순으로\n","\n","ct = 0\n","\n","for child in resnet.children():\n","    ct += 1\n","\n","    if ct < 6:  # 0~5번까지는 그대로, 6~9번 레이어는 학습을 해라\n","        for param in child.parameters():\n","            param.requires_grad = True  # False가 맞는거 같은데 오류 발생함 (위에서 살펴봤을때, layer 개수가 10개가 아니고 1개로 나옴)"],"metadata":{"id":"OINZkPsJiWq1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in tqdm(range(epochs)):\n","    for step, (before_image, after_image, time_delta) in tqdm(enumerate(train_data_loader)):\n","        before_image = before_image.to(device)\n","        after_image = after_image.to(device)\n","        time_delta = time_delta.to(device)\n","\n","        optimizer_ft.zero_grad()\n","        logit = resnet(before_image, after_image)\n","        print(logit.squeeze(1).float())\n","        print(logit.float().shape)\n","        \n","        print(time_delta.float())\n","        print(time_delta.float().shape)\n","\n","        train_loss = (torch.sum(torch.abs(logit.squeeze(1).float() - time_delta.float())) /\n","                      torch.LongTensor([batch_size]).squeeze(0).to(device))\n","        print(type(train_loss))\n","        train_loss.backward()\n","        optimizer_ft.step()\n","\n","        if step % 15 == 0:\n","            print('\\n=====================loss=======================')\n","            print(f'\\n=====================EPOCH: {epoch}=======================')\n","            print(f'\\n=====================step: {step}=======================')\n","            print('MAE_loss : ', train_loss.detach().cpu().numpy())\n","\n","    valid_losses = []\n","    with torch.no_grad():\n","        for valid_before, valid_after, time_delta in tqdm(valid_data_loader):\n","            valid_before = valid_before.to(device)\n","            valid_after = valid_after.to(device)\n","            valid_time_delta = time_delta.to(device)\n","\n","\n","            logit = resnet(valid_before, valid_after)\n","            valid_loss = (torch.sum(torch.abs(logit.squeeze(1).float() - valid_time_delta.float())) /\n","                          torch.LongTensor([valid_batch_size]).squeeze(0).to(device))\n","            valid_losses.append(valid_loss.detach().cpu())\n","\n","\n","    print(f'VALIDATION_LOSS MAE : {sum(valid_losses)/len(valid_losses)}')\n","    checkpoiont = {\n","        'model': resnet.state_dict(),\n","\n","    }\n","\n"],"metadata":{"id":"UY400zj28Nxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(checkpoiont, 'resnet50_ver1.pt')"],"metadata":{"id":"UaFfS2YVCdzQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict test data set"],"metadata":{"id":"XHyFH_j7B5KA"}},{"cell_type":"code","source":["transform_resNet = transforms.Compose([\n","    transforms.Resize([256,256]),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","])\n","\n","test_resNet = ImageFolder(root = './data/splitted/test', transform = transform_resNet)\n","test_loader_resNet = torch.utils.data.DataLoader(test_resNet,\n","                                                 batch_size = batch_size,\n","                                                 shuffle = True,\n","                                                 num_workers = 2)\n"],"metadata":{"id":"_5dBO0T6iWhE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet50 = torch.load('./code/resnet50.pt')\n","resnet50.eval()\n","\n","test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n","\n","print('ResNet test acc : ', test_accuracy)"],"metadata":{"id":"u4dn87CoiWe2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640186092206,"user_tz":-540,"elapsed":303081,"user":{"displayName":"유상준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwhV3OPaZeVbcnb0L540CX4dtB2wGRfCVw4E8=s64","userId":"06620102043085366517"}},"outputId":"f00f7e7e-2917-4092-e40a-f40b16cc3aad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet test acc :  96.8212415856395\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"g2W3ZgpM8Ns6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8BaTjToT8NqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"30yUK2sm8Nnk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"N1HHeg4J8Nld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"yd8El0g_8Njl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"aQXNKN2-8Ngf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Lt2ZRsmZ8Nd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"uIBEkeQu8Nbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"kYQSbqmF8NY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"6xoEOCOi8NWS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9a5dfOFH8NUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"u6BaUVvl8NRO"},"execution_count":null,"outputs":[]}]}